pub_date	title	venue	excerpt	citation	site_url	paper_url
2019/6/8	Domain Adaptive Dialog Generation via Meta Learning	ACL 2019	Domain adaptation is an essential task in dialog system building because there are so many new dialog tasks created for different needs every day. Collecting and annotating training data for these new tasks is costly since it involves real user interactions. We propose a domain adaptive dialog generation method based on meta-learning (DAML). DAML is an end-to-end trainable dialog system model that learns from multiple rich-resource tasks and then adapts to new domains with minimal training samples. We train a dialog system model using multiple rich-resource single-domain dialog data by applying the model-agnostic meta-learning algorithm to dialog domain. The model is capable of learning a competitive dialog system on a new domain with only a few training examples in an efficient manner. The two-step gradient updates in DAML enable the model to learn general features across multiple tasks. We evaluate our method on a simulated dialog dataset and achieve state-of-the-art performance, which is generalizable to new tasks.	@inproceedings{Qian2019DomainAD, title={Domain Adaptive Dialog Generation via Meta Learning}, author={Kun Qian and Zhou Yu}, booktitle={Annual Meeting of the Association for Computational Linguistics}, year={2019}, url={https://api.semanticscholar.org/CorpusID:182952555} }		https://arxiv.org/abs/1906.03520
2019/9/3	How to Build User Simulators to Train RL-based Dialog Systems	EMNLP 2019	User simulators are essential for training reinforcement learning (RL) based dialog models. The performance of the simulator directly impacts the RL policy. However, building a good user simulator that models real user behaviors is challenging. We propose a method of standardizing user simulator building that can be used by the community to compare dialog system quality using the same set of user simulators fairly. We present implementations of six user simulators trained with different dialog planning and generation methods. We then calculate a set of automatic metrics to evaluate the quality of these simulators both directly and indirectly. We also ask human users to assess the simulators directly and indirectly by rating the simulated dialogs and interacting with the trained systems. This paper presents a comprehensive evaluation framework for user simulator study and provides a better understanding of the pros and cons of different user simulators, as well as their impacts on the trained systems.	@inproceedings{Shi2019HowTB, title={How to Build User Simulators to Train RL-based Dialog Systems}, author={Weiyan Shi and Kun Qian and Xuewei Wang and Zhou Yu}, booktitle={Conference on Empirical Methods in Natural Language Processing}, year={2019}, url={https://api.semanticscholar.org/CorpusID:202540313} }		https://arxiv.org/abs/1909.01388
2020/4/3	End-to-end trainable non-collaborative dialog system	AAAI 2020	End-to-end task-oriented dialog models have achieved promising performance on collaborative tasks where users willingly coordinate with the system to complete a given task. While in non-collaborative settings, for example, negotiation and persuasion, users and systems do not share a common goal. As a result, compared to collaborate tasks, people use social content to build rapport and trust in these non-collaborative settings in order to advance their goals. To handle social content, we introduce a hierarchical intent annotation scheme, which can be generalized to different non-collaborative dialog tasks. Building upon TransferTransfo (Wolf et al. 2019), we propose an end-to-end neural network model to generate diverse coherent responses. Our model utilizes intent and semantic slots as the intermediate sentence representation to guide the generation process. In addition, we design a filter to select appropriate responses based on whether these intermediate representations fit the designed task and conversation constraints. Our non-collaborative dialog model guides users to complete the task while simultaneously keeps them engaged. We test our approach on our newly proposed AntiScam dataset and an existing PersuasionForGood dataset. Both automatic and human evaluations suggest that our model outperforms multiple baselines in these two non-collaborative tasks.	@article{Li2019EndtoEndTN, title={End-to-End Trainable Non-Collaborative Dialog System}, author={Yu Li and Kun Qian and Weiyan Shi and Zhou Yu}, journal={ArXiv}, year={2019}, volume={abs/1911.10742}, url={https://api.semanticscholar.org/CorpusID:208268255} }		https://arxiv.org/abs/1911.10742
2020/10/14	Memformer: A memory-augmented transformer for sequence modeling	arXiv	Transformers have reached remarkable success in sequence modeling. However, these models have efficiency issues as they need to store all the history token-level representations as memory. We present Memformer, an efficient neural network for sequence modeling, that utilizes an external dynamic memory to encode and retrieve past information. Our model achieves linear time complexity and constant memory space complexity when processing long sequences. We also propose a new optimization scheme, memory replay back-propagation (MRBP), which promotes long-range back-propagation through time with a significantly reduced memory requirement. Experimental results show that Memformer has achieved comparable performance compared to the baselines by using 8.1x less memory space and 3.2x faster on inference. Analysis of the attention pattern shows that our external memory slots can encode and retain important information through timesteps.	@inproceedings{Wu2020MemformerAM, title={Memformer: A Memory-Augmented Transformer for Sequence Modeling}, author={Qingyang Wu and Zhenzhong Lan and Kun Qian and Jing Gu and Alborz Geramifard and Zhou Yu}, booktitle={AACL/IJCNLP}, year={2020}, url={https://api.semanticscholar.org/CorpusID:248157404} }		https://arxiv.org/abs/2010.06891
2021/4/6	A Student-Teacher Architecture for Dialog Domain Adaptation under the Meta-Learning Setting	AAAI 2021	Numerous new dialog domains are being created every day while collecting data for these domains is extremely costly since it involves human interactions. Therefore, it is essential to develop algorithms that can adapt to different domains efficiently when building data-driven dialog models. The most recent researches on domain adaption focus on giving the model a better initialization, rather than optimizing the adaptation process. We propose an efficient domain adaptive task-oriented dialog system model, which incorporates a meta-teacher model to emphasize the different impacts between generated tokens with respect to the context. We first train our base dialog model and meta-teacher model adversarially in a meta-learning setting on rich-resource domains. The meta-teacher learns to quantify the importance of tokens under different contexts across different domains. During adaptation, the meta-teacher guides the dialog model to focus on important tokens in order to achieve better adaptation efficiency. We evaluate our model on two multi-domain datasets, MultiWOZ and Google Schema-Guided Dialogue, and achieve state-of-the-art performance.	@article{Qian2021ASA, title={A Student-Teacher Architecture for Dialog Domain Adaptation under the Meta-Learning Setting}, author={Kun Qian and Wei Wei and Zhou Yu}, journal={ArXiv}, year={2021}, volume={abs/2104.02689}, url={https://api.semanticscholar.org/CorpusID:233033692} }		https://arxiv.org/abs/2104.02689
2021/5/29	Annotation Inconsistency and Entity Bias in MultiWOZ	SIGDIAL 2021	MultiWOZ is one of the most popular multi-domain task-oriented dialog datasets, containing 10K+ annotated dialogs covering eight domains. It has been widely accepted as a benchmark for various dialog tasks, e.g., dialog state tracking (DST), natural language generation (NLG), and end-to-end (E2E) dialog modeling. In this work, we identify an overlooked issue with dialog state annotation inconsistencies in the dataset, where a slot type is tagged inconsistently across similar dialogs leading to confusion for DST modeling. We propose an automated correction for this issue, which is present in a whopping 70% of the dialogs. Additionally, we notice that there is significant entity bias in the dataset (e.g., "cambridge" appears in 50% of the destination cities in the train domain). The entity bias can potentially lead to named entity memorization in generative models, which may go unnoticed as the test set suffers from a similar entity bias as well. We release a new test set with all entities replaced with unseen entities. Finally, we benchmark joint goal accuracy (JGA) of the state-of-the-art DST baselines on these modified versions of the data. Our experiments show that the annotation inconsistency corrections lead to 7-10% improvement in JGA. On the other hand, we observe a 29% drop in JGA when models are evaluated on the new test set with unseen entities.	@article{Qian2021AnnotationIA, title={Annotation Inconsistency and Entity Bias in MultiWOZ}, author={Kun Qian and Ahmad Beirami and Zhouhan Lin and Ankita De and Alborz Geramifard and Zhou Yu and Chinnadhurai Sankar}, journal={ArXiv}, year={2021}, volume={abs/2105.14150}, url={https://api.semanticscholar.org/CorpusID:235254332} }		https://arxiv.org/abs/2105.14150
2021/12/25	Database Search Results Disambiguation for Task-Oriented Dialog Systems	NAACL 2022	As task-oriented dialog systems are becoming increasingly popular in our lives, more realistic tasks have been proposed and explored. However, new practical challenges arise. For instance, current dialog systems cannot effectively handle multiple search results when querying a database, due to the lack of such scenarios in existing public datasets. In this paper, we propose Database Search Result (DSR) Disambiguation, a novel task that focuses on disambiguating database search results, which enhances user experience by allowing them to choose from multiple options instead of just one. To study this task, we augment the popular task-oriented dialog datasets (MultiWOZ and SGD) with turns that resolve ambiguities by (a) synthetically generating turns through a pre-defined grammar, and (b) collecting human paraphrases for a subset. We find that training on our augmented dialog data improves the model's ability to deal with ambiguous scenarios, without sacrificing performance on unmodified turns. Furthermore, pre-fine tuning and multi-task learning help our model to improve performance on DSR-disambiguation even in the absence of in-domain data, suggesting that it can be learned as a universal dialog skill. Our data and code will be made publicly available.	@article{Qian2021DatabaseSR, title={Database Search Results Disambiguation for Task-Oriented Dialog Systems}, author={Kun Qian and Ahmad Beirami and Satwik Kottur and Shahin Shayandeh and Paul A. Crook and Alborz Geramifard and Zhou Yu and Chinnadhurai Sankar}, journal={ArXiv}, year={2021}, volume={abs/2112.08351}, url={https://api.semanticscholar.org/CorpusID:245144925} }		https://arxiv.org/abs/2112.08351
2021/12/15	AllWOZ: Towards Multilingual Task-Oriented Dialog Systems for All	arXiv	A commonly observed problem of the state-of-the-art natural language technologies, such as Amazon Alexa and Apple Siri, is that their services do not extend to most developing countries' citizens due to language barriers. Such populations suffer due to the lack of available resources in their languages to build NLP products. This paper presents AllWOZ, a multilingual multi-domain task-oriented customer service dialog dataset covering eight languages: English, Mandarin, Korean, Vietnamese, Hindi, French, Portuguese, and Thai. Furthermore, we create a benchmark for our multilingual dataset by applying mT5 with meta-learning.	@article{Zuo2021AllWOZTM, title={AllWOZ: Towards Multilingual Task-Oriented Dialog Systems for All}, author={Lei Zuo and Kun Qian and Bowen Yang and Zhou Yu}, journal={ArXiv}, year={2021}, volume={abs/2112.08333}, url={https://api.semanticscholar.org/CorpusID:245144815} }		https://arxiv.org/abs/2112.08333
2022/5/25	Learning a better initialization for soft prompts via meta-learning	AACL 2023	Prompt tuning (PT) is an effective approach to adapting pre-trained language models to downstream tasks. Without a good initialization, prompt tuning doesn't perform well under few-shot settings. So pre-trained prompt tuning (PPT) is proposed to initialize prompts by leveraging pre-training data. We propose MetaPT (Meta-learned Prompt Tuning) to further improve PPT's initialization by considering latent structure within the pre-training data. Specifically, we introduce the structure by first clustering pre-training data into different auxiliary tasks with unsupervised methods. Then we use these tasks to pre-train prompts with a meta-learning algorithm. Such a process can make prompts learn a better initialization by discovering commonalities among these auxiliary tasks. We evaluate our method on seven downstream tasks. Our MetaPT achieves better and more stable performance than the state-of-the-art method.	@article{Huang2022LearningAB, title={Learning a Better Initialization for Soft Prompts via Meta-Learning}, author={Yukun Huang and Kun Qian and Zhou Yu}, journal={ArXiv}, year={2022}, volume={abs/2205.12471}, url={https://api.semanticscholar.org/CorpusID:249062905} }		https://arxiv.org/abs/2205.12471
2022/11/30	KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning	EMNLP 2023	In task-oriented dialogs (TOD), reinforcement learning (RL) algorithms train a model to directly optimize response for task-related metrics. However, RL needs to perform exploration, which can be time-consuming due to the slow auto-regressive sequence generation process. We investigate an approach to create a more efficient RL-based algorithm to improve TOD performance in an offline setting. First, we use a faster generation procedure that samples from independent next-word distributions after training the language model (LM) with supervised learning. We then introduce a fine-grained reward function to help the model focus on learning key information in a dialog, by measuring the importance and semantic closeness of each generated token. Experiments on the MultiWoZ dataset show our new training algorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), achieves state-of-the-art performance on the end-to-end response generation task, with a 15% training time reduction compared to a standard RL algorithm using auto-regressive generation.	@inproceedings{Yu2022KRLSIE, title={KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning}, author={Xiao Yu and Qingyang Wu and Kun Qian and Zhou Yu}, year={2022}, url={https://api.semanticscholar.org/CorpusID:254877771} }		https://arxiv.org/abs/2211.16773
2023/2/12	Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking	EACL 2023	Prompt-based methods with large pre-trained language models (PLMs) have shown impressive unaided performance across many NLP tasks. These models improve even further with the addition of a few labeled in-context exemplars to guide output generation. However, for more complex tasks such as dialogue state tracking (DST), designing prompts that reliably convey the desired intent is nontrivial, leading to unstable results. Furthermore, building in-context exemplars for dialogue tasks is difficult because conversational contexts are long while model input lengths are relatively short. To overcome these issues we first adapt a meta-learning scheme to the dialogue domain which stabilizes the ability of the model to perform well under various prompts. We additionally design a novel training method to improve upon vanilla retrieval mechanisms to find ideal in-context examples. Finally, we introduce a saliency model to limit dialogue text length, allowing us to include more exemplars per query. In effect, we are able to achieve highly competitive results for few-shot DST on MultiWOZ.	@inproceedings{Chen2023StabilizedIL, title={Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking}, author={Derek Chen and Kun Qian and Zhou Yu}, booktitle={Findings}, year={2023}, url={https://api.semanticscholar.org/CorpusID:256826986} }		https://arxiv.org/abs/2302.05932
2023/4/11	User Adaptive Language Learning Chatbots with a Curriculum	AIED 2023	Along with the development of systems for natural language understanding and generation, dialog systems have been widely adopted for language learning and practicing. Many current educational dialog systems perform chitchat, where the generated content and vocabulary are not constrained. However, for learners in a school setting, practice through dialog is more effective if it aligns with students' curriculum and focuses on textbook vocabulary. Therefore, we adapt lexically constrained decoding to a dialog system, which urges the dialog system to include curriculum-aligned words and phrases in its generated utterances. We adopt a generative dialog system, BlenderBot3, as our backbone model and evaluate our curriculum-based dialog system with middle school students learning English as their second language. The constrained words and phrases are derived from their textbooks, suggested by their English teachers. The evaluation result demonstrates that the dialog system with curriculum infusion improves students' understanding of target words and increases their interest in practicing English.	@inproceedings{Qian2023UserAL, title={User Adaptive Language Learning Chatbots with a Curriculum}, author={Kun Qian and Ryan Shea and Yu Li and Luke K. Fryer and Zhou Yu}, booktitle={International Conference on Artificial Intelligence in Education}, year={2023}, url={https://api.semanticscholar.org/CorpusID:258078794} }		https://arxiv.org/abs/2304.05489
2023/7/19	DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI	arXiv	Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness. To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information. Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training. To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-shot and few-shot learning scenarios demonstrate the superiority of DialogStudio. To improve transparency and support dataset and task-based research, as well as language model pre-training, all datasets, licenses, codes, and models associated with DialogStudio are made publicly accessible at https://github.com/salesforce/DialogStudio	@article{Zhang2023DialogStudioTR, title={DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI}, author={Jianguo Zhang and Kun Qian and Zhiwei Liu and Shelby Heinecke and Rui Meng and Ye Liu and Zhou Yu and Silvio Savarese and Caiming Xiong}, journal={ArXiv}, year={2023}, volume={abs/2307.10172}, url={https://api.semanticscholar.org/CorpusID:259982944} }		https://arxiv.org/abs/2307.10172
2023/8/16	Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System	SIGDIAL 2023	End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios. Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.	@inproceedings{Zhang2023EnhancingPO, title={Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System}, author={Jianguo Zhang and Stephen Roller and Kun Qian and Zhiwei Liu and Rui Meng and Shelby Heinecke and Haiquan Wang and Silvio Savarese and Caiming Xiong}, booktitle={SIGDIAL Conferences}, year={2023}, url={https://api.semanticscholar.org/CorpusID:260926661} }		https://arxiv.org/abs/2308.08169